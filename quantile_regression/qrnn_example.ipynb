{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantile Regression\n",
    "こちらの追試 https://github.com/ceshine/quantile-regression-tensorflow/blob/master/notebooks/03-sklearn-example-pytorch.ipynb\n",
    "https://medium.com/the-artificial-impostor/quantile-regression-part-2-6fdbc26b2629"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from itertools import chain\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_formats = {'png', 'retina'}\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "class data_gen:\n",
    "    def __init__(self, mu, sigma):\n",
    "        \"\"\"\n",
    "        args\n",
    "            mu, sigma ... function\n",
    "        \"\"\"\n",
    "        self.mu=mu\n",
    "        self.sigma=sigma\n",
    "    \n",
    "    def generate_with_noise(self, x):\n",
    "        return self.mu(x) + np.random.normal(0, self.sigma(x))\n",
    "\n",
    "    def show_mu(self):\n",
    "        x=np.linspace(-1.5,1.5,num=100)\n",
    "        y=self.mu(x)\n",
    "        plt.plot(x,y,label=\"mean\")\n",
    "        upper = y+self.sigma(x)\n",
    "        lower = y-self.sigma(x)\n",
    "        plt.fill_between(x,lower,upper,color=\"blue\",alpha=0.1, label=\"std\")\n",
    "        \n",
    "        for t in [0.05, 0.15, 0.3, 0.7, 0.85, 0.95]:\n",
    "            plt.plot(x, self.t_quantile(t,x), label=str(t)+\"-quantile\")\n",
    "        \n",
    "        plt.legend(bbox_to_anchor=(0, -0.1), loc='upper left', borderaxespad=0, fontsize=12)\n",
    "        plt.ylim([-3,3]);\n",
    "    \n",
    "    def t_quantile(self, t, x):\n",
    "        \"\"\"\n",
    "        return tau-quantile\n",
    "        args\n",
    "            t ... tau-quantile's tau\n",
    "            x ... input feature\n",
    "        \"\"\"\n",
    "        return norm.ppf(q=t, loc=self.mu(x), scale=self.sigma(x))\n",
    "        \n",
    "def mu(x):\n",
    "    #from [Takeuchi et.al, 2003]\n",
    "    return np.sinc(x)\n",
    "\n",
    "def sigma(x):\n",
    "    return 0.1*np.exp(1-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = data_gen(mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen.show_mu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------\n",
    "#  First the noiseless case\n",
    "X = np.atleast_2d(np.random.uniform(-1.5, 1.5, size=1000)).T\n",
    "X = X.astype(np.float32)\n",
    "X.sort(axis=0)\n",
    "# Observations\n",
    "# y = gen.mu(X)\n",
    "y = gen.generate_with_noise(X)\n",
    "\n",
    "# Mesh the input space for evaluations of the real function, the prediction and\n",
    "# its MSE\n",
    "xx = np.atleast_2d(np.linspace(0, 10, 1000)).T\n",
    "xx = xx.astype(np.float32)\n",
    "\n",
    "X.shape, y.shape, xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0],y)\n",
    "plt.ylim([-3,3]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class q_model_simplified(nn.Module):\n",
    "    def __init__(self,\n",
    "                 quantiles,\n",
    "                 in_shape=1,\n",
    "                 dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.quantiles = quantiles\n",
    "        self.num_quantiles = len(quantiles)\n",
    "        \n",
    "        self.in_shape = in_shape\n",
    "        self.out_shape = len(quantiles)\n",
    "        self.dropout = dropout\n",
    "        self.build_model()\n",
    "        self.init_weights()\n",
    "        \n",
    "    def build_model(self): \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(self.in_shape, 64),\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm1d(64),\n",
    "            nn.Dropout(self.dropout),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            # nn.BatchNorm1d(128),\n",
    "            nn.Dropout(self.dropout),\n",
    "            nn.Linear(128, self.out_shape) #最後のノード数だけもつ層を作る\n",
    "        )\n",
    "        \n",
    "    def init_weights(self):\n",
    "        for m in self.model:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.orthogonal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantileLoss(nn.Module):\n",
    "    def __init__(self, quantiles):\n",
    "        super().__init__()\n",
    "        self.quantiles = quantiles\n",
    "        \n",
    "    def forward(self, preds, target):\n",
    "        assert not target.requires_grad\n",
    "        assert preds.size(0) == target.size(0)\n",
    "        losses = []\n",
    "        for i, q in enumerate(quantiles):\n",
    "            errors = target - preds[:, i]\n",
    "            losses.append(torch.max((q-1) * errors, q * errors).unsqueeze(1))\n",
    "        loss = torch.mean(torch.sum(torch.cat(losses, dim=1), dim=1))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner:\n",
    "    def __init__(self, model, optimizer_class, loss_func, device='cpu'):\n",
    "        self.model = model.to(device)\n",
    "        self.optimizer = optimizer_class(self.model.parameters())\n",
    "        self.loss_func = loss_func.to(device)\n",
    "        self.device = device\n",
    "        self.loss_history = []\n",
    "        \n",
    "    def fit(self, x, y, epochs, batch_size):\n",
    "        self.model.train()\n",
    "        for e in range(epochs):\n",
    "            shuffle_idx = np.arange(x.shape[0])\n",
    "            np.random.shuffle(shuffle_idx)\n",
    "            x = x[shuffle_idx]\n",
    "            y = y[shuffle_idx]\n",
    "            epoch_losses = []\n",
    "            for idx in range(0, x.shape[0], batch_size):\n",
    "                self.optimizer.zero_grad()\n",
    "                batch_x = torch.from_numpy(\n",
    "                    x[idx : min(idx + batch_size, x.shape[0]),:]\n",
    "                ).float().to(self.device).requires_grad_(False)\n",
    "                batch_y = torch.from_numpy(\n",
    "                    y[idx : min(idx + batch_size, y.shape[0])]\n",
    "                ).float().to(self.device).requires_grad_(False)\n",
    "                preds = self.model(batch_x)\n",
    "                loss = loss_func(preds, batch_y)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                epoch_losses.append(loss.cpu().detach().numpy())                                \n",
    "            epoch_loss =  np.mean(epoch_losses)\n",
    "            self.loss_history.append(epoch_loss)\n",
    "            if (e+1) % 500 == 0:\n",
    "                print(\"Epoch {}: {}\".format(e+1, epoch_loss))\n",
    "                \n",
    "    def predict(self, x, mc=False):\n",
    "        if mc:\n",
    "            self.model.train()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "        return self.model(torch.from_numpy(x).to(self.device).requires_grad_(False)).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "quantiles = [.15, .5, .85]\n",
    "model = q_model_simplified(quantiles, dropout=0.1)\n",
    "loss_func = QuantileLoss(quantiles)\n",
    "learner = Learner(model, partial(torch.optim.Adam, weight_decay=1e-6), loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training\n",
    "epochs = 10000\n",
    "learner.fit(X, y, epochs, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the prediction on the meshed x-axis\n",
    "tmp = learner.predict(xx)\n",
    "y_lower, y_pred, y_upper = tmp[:, 0], tmp[:, 1], tmp[:, 2]\n",
    "\n",
    "# Plot the function, the prediction and the 90% confidence interval based on\n",
    "# the MSE\n",
    "fig = plt.figure()\n",
    "plt.plot(xx, f(xx), 'g:', label=u'$f(x) = x\\,\\sin(x)$')\n",
    "plt.plot(X, y, 'b.', markersize=10, label=u'Observations')\n",
    "plt.plot(xx, y_pred, 'r-', label=u'Prediction')\n",
    "plt.plot(xx, y_upper, 'k-')\n",
    "plt.plot(xx, y_lower, 'k-')\n",
    "plt.fill(np.concatenate([xx, xx[::-1]]),\n",
    "         np.concatenate([y_upper, y_lower[::-1]]),\n",
    "         alpha=.5, fc='b', ec='None', label='70% prediction interval')\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$f(x)$')\n",
    "plt.ylim(-10, 20)\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xx,f(xx),'g', label=u'$f(x) = x\\,\\sin(x)$')\n",
    "plt.ylim(-10, 20)\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$f(x)$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
