{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantile Regression\n",
    "こちらの追試 https://github.com/ceshine/quantile-regression-tensorflow/blob/master/notebooks/03-sklearn-example-pytorch.ipynb\n",
    "https://medium.com/the-artificial-impostor/quantile-regression-part-2-6fdbc26b2629"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from itertools import chain\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_formats = {'png', 'retina'}\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "np.random.seed(1)\n",
    "\n",
    "def f(x):\n",
    "    \"\"\"The function to predict.\"\"\"\n",
    "    return x * np.sin(x)\n",
    "\n",
    "def sigma(x):\n",
    "    return 3*np.exp(0.3*(1-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------\n",
    "#  First the noiseless case\n",
    "X = np.atleast_2d(np.random.uniform(0, 10.0, size=500)).T\n",
    "X = X.astype(np.float32)\n",
    "# X.sort(axis=0)\n",
    "# Observations\n",
    "y = f(X).ravel()\n",
    "\n",
    "noise = np.random.normal(loc=0, scale=sigma(X).reshape(-1))\n",
    "y += noise\n",
    "y = y.astype(np.float32)\n",
    "\n",
    "# Mesh the input space for evaluations of the real function, the prediction and\n",
    "# its MSE\n",
    "xx = np.atleast_2d(np.linspace(0, 10, 100)).T\n",
    "xx = xx.astype(np.float32)\n",
    "\n",
    "X.shape, y.shape, xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0],y,s=5)\n",
    "plt.ylim(-10, 10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "def t_quantile(t, x):\n",
    "    return norm.ppf(q=t,loc=f(x), scale=sigma(x))\n",
    "\n",
    "for t,m in zip([.15, 0.5, 0.85],['b-','r-','g-']):\n",
    "    plt.plot(np.linspace(0, 10, 100),t_quantile(t,xx),m,label=str(t)+'-quantile')\n",
    "plt.legend()\n",
    "plt.ylim(-10, 10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class q_model_simplified(nn.Module):\n",
    "    def __init__(self,\n",
    "                 quantiles,\n",
    "                 in_shape=1,\n",
    "                 dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.quantiles = quantiles\n",
    "        self.num_quantiles = len(quantiles)\n",
    "        \n",
    "        self.in_shape = in_shape\n",
    "        self.out_shape = len(quantiles)\n",
    "        self.dropout = dropout\n",
    "        self.build_model()\n",
    "        self.init_weights()\n",
    "        \n",
    "    def build_model(self): \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(self.in_shape, 64),\n",
    "            nn.ReLU(),\n",
    "#             nn.BatchNorm1d(64),\n",
    "#             nn.Dropout(self.dropout),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "#             nn.BatchNorm1d(128),\n",
    "#             nn.Dropout(self.dropout),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "#             nn.BatchNorm1d(128),\n",
    "#             nn.Dropout(self.dropout),\n",
    "            nn.Linear(128, self.out_shape) #最後のノード数だけもつ層を作る\n",
    "        )\n",
    "        \n",
    "    def init_weights(self):\n",
    "        for m in self.model:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.orthogonal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantileLoss(nn.Module):\n",
    "    def __init__(self, quantiles):\n",
    "        super().__init__()\n",
    "        self.quantiles = quantiles\n",
    "        \n",
    "    def forward(self, preds, target):\n",
    "        assert not target.requires_grad\n",
    "        assert preds.size(0) == target.size(0)\n",
    "        losses = []\n",
    "        for i, q in enumerate(quantiles):\n",
    "            errors = target - preds[:, i]\n",
    "            losses.append(torch.max((q-1) * errors, q * errors).unsqueeze(1))\n",
    "        loss = torch.mean(torch.sum(torch.cat(losses, dim=1), dim=1))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner:\n",
    "    def __init__(self, model, optimizer_class, loss_func, device='cpu'):\n",
    "        self.model = model.to(device)\n",
    "        self.optimizer = optimizer_class(self.model.parameters())\n",
    "        self.loss_func = loss_func.to(device)\n",
    "        self.device = device\n",
    "        self.loss_history = []\n",
    "        \n",
    "    def fit(self, x, y, epochs, batch_size):\n",
    "        self.model.train()\n",
    "        for e in range(epochs):\n",
    "            shuffle_idx = np.arange(x.shape[0])\n",
    "            np.random.shuffle(shuffle_idx)\n",
    "            x = x[shuffle_idx]\n",
    "            y = y[shuffle_idx]\n",
    "            epoch_losses = []\n",
    "            for idx in range(0, x.shape[0], batch_size):\n",
    "                self.optimizer.zero_grad()\n",
    "                batch_x = torch.from_numpy(\n",
    "                    x[idx : min(idx + batch_size, x.shape[0]),:]\n",
    "                ).float().to(self.device).requires_grad_(False)\n",
    "                batch_y = torch.from_numpy(\n",
    "                    y[idx : min(idx + batch_size, y.shape[0])]\n",
    "                ).float().to(self.device).requires_grad_(False)\n",
    "                preds = self.model(batch_x)\n",
    "                loss = loss_func(preds, batch_y)\n",
    "#                 print(loss)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                epoch_losses.append(loss.cpu().detach().numpy())                                \n",
    "            epoch_loss =  np.mean(epoch_losses)\n",
    "            self.loss_history.append(epoch_loss)\n",
    "            if (e+1) % 500 == 0:\n",
    "                print(\"Epoch {}: {}\".format(e+1, epoch_loss))\n",
    "                \n",
    "    def predict(self, x, mc=False):\n",
    "        if mc:\n",
    "            self.model.train()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "        return self.model(torch.from_numpy(x).to(self.device).requires_grad_(False)).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "quantiles = [.15, .5, .85]\n",
    "model = q_model_simplified(quantiles, dropout=0.1)\n",
    "loss_func = QuantileLoss(quantiles)\n",
    "learner = Learner(model, partial(torch.optim.Adam, weight_decay=1e-8), loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training\n",
    "epochs = 500\n",
    "learner.fit(X, y, epochs, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(learner.loss_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the prediction on the meshed x-axis\n",
    "tmp = learner.predict(xx)\n",
    "y_lower, y_pred, y_upper = tmp[:, 0], tmp[:, 1], tmp[:, 2]\n",
    "\n",
    "# Plot the function, the prediction and the 90% confidence interval based on\n",
    "# the MSE\n",
    "fig = plt.figure()\n",
    "plt.plot(xx, f(xx), 'g:', label=u'$f(x) = x\\,\\sin(x)$')\n",
    "# plt.plot(X, y, 'b.', markersize=5, label=u'Observations')\n",
    "plt.plot(xx, y_lower, 'b-', label='0.15-quantile')\n",
    "plt.plot(xx, y_pred, 'r-', label='0.5-quantile')\n",
    "plt.plot(xx, y_upper, 'g-', label='0.85-quantile')\n",
    "plt.fill(np.concatenate([xx, xx[::-1]]),\n",
    "         np.concatenate([y_upper, y_lower[::-1]]),\n",
    "         alpha=.3, fc='b', ec='None', label='70% prediction interval')\n",
    "plt.xlabel('$x$')\n",
    "# plt.ylabel('$f(x)$')\n",
    "plt.ylim(-10, 10)\n",
    "plt.legend(bbox_to_anchor=(0, -0.1), loc='upper left', borderaxespad=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xx,f(xx),'g', label=u'$f(x) = x\\,\\sin(x)$')\n",
    "plt.ylim(-10, 20)\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$f(x)$');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
