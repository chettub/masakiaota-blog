{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### アイデア\n",
    "ガウス分布で回帰する。\n",
    "\n",
    "出力にパラメトライゼーショントリックを用いて、サンプルされたzを出力するようにする。\n",
    "そのzがなるべく次時刻の真の値と近いものになるようにすれば、分散込みで学習できるのでは？というアイデア\n",
    "\n",
    "いろいろ工夫してみたがだめだった"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    print(\"loading the data...\")\n",
    "    DATA_DIR=\"./data/\"\n",
    "    X_train = np.load(os.path.join(DATA_DIR, \"X_train.npy\"))\n",
    "    print(\"X train\",X_train.shape)\n",
    "    X_test = np.load(os.path.join(DATA_DIR, \"X_test.npy\"))\n",
    "    print(\"X test\",X_test.shape)\n",
    "    y_train = np.load(os.path.join(DATA_DIR, \"y_train.npy\"))\n",
    "    print(\"y train\",y_train.shape)\n",
    "    y_test = np.load(os.path.join(DATA_DIR, \"y_test.npy\"))\n",
    "    print(\"y test\",y_test.shape)\n",
    "    \n",
    "    # shapeをglobal変数に\n",
    "    global NUM_timesteps, NUM_input_dim, NUM_output_dim\n",
    "    _, NUM_timesteps, NUM_input_dim = X_train.shape\n",
    "    _, NUM_output_dim = y_train.shape\n",
    "    \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, RepeatVector, Input, Lambda\n",
    "from keras.layers import GRU\n",
    "# from keras.layers import CuDNNGRU as GRU #GPU用\n",
    "from keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from keras.optimizers import adam\n",
    "from keras import backend as K\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_model():\n",
    "    \"\"\"\n",
    "    GRU\n",
    "    GRU\n",
    "    FC\n",
    "    FC\n",
    "    ↓  ↓\n",
    "    mu sigma\n",
    "    \n",
    "    oをサンプリング\n",
    "    \n",
    "    というモデルを返す\n",
    "    \"\"\"\n",
    "    def sampling(args):\n",
    "        \"\"\"\n",
    "        z_mean, z_log_var=argsからoをサンプリングする関数\n",
    "        戻り値\n",
    "            o (tf.tensor):サンプリングされた結果\n",
    "        \"\"\"\n",
    "        z_mean, z_log_var = args\n",
    "        # いきなり標準偏差を求めてしまっても構わないが、負を許容してしまうのでこのようなトリックを用いている\n",
    "        batch_size = K.shape(z_mean)[0]\n",
    "        eps = K.random_normal(shape=(batch_size,100))\n",
    "        return z_mean + K.exp(0.5*z_log_var)*eps   \n",
    "    \n",
    "    \n",
    "    # hyper parameter\n",
    "    LATENT = 20\n",
    "    FC=20\n",
    "    \n",
    "    # ネットワークの定義\n",
    "    inputs = Input(shape=(NUM_timesteps, NUM_input_dim))\n",
    "    # (, NUM_timesteps, NUM_input_dim)\n",
    "    gru=GRU(LATENT, return_sequences=True)(inputs)\n",
    "    # (, NUM_timesteps, LATENT)\n",
    "    gru=GRU(LATENT)(gru)\n",
    "    # (, LATENT)\n",
    "    fc=Dense(FC)(gru)\n",
    "    # (, FC)\n",
    "    o_mean=Dense(NUM_output_dim,name=\"mean\")(fc)\n",
    "    o_log_var=Dense(NUM_output_dim,name=\"log_var\")(fc)\n",
    "    # 双方とも(, NUM_output_dim)\n",
    "    output = Lambda(sampling, output_shape=(100,),name=\"output\")\\\n",
    "    ([o_mean,o_log_var])\n",
    "    # (,100)\n",
    "    \n",
    "    model = Model(inputs,output)    \n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ret_model()\n",
    "# def loss(y_true, pred):\n",
    "#     \"\"\"\n",
    "#     predは2つの出力を持つ\n",
    "#     \"\"\"\n",
    "#     mean, log_var = pred[0], pred[1]\n",
    "#     sigma=K.exp(0.5*log_var)\n",
    "#     loss = 0.5+K.log(2*np.pi*sigma)+(y_true-mean)/(np.sqrt(2)*sigma)\n",
    "#     #勾配消失してしまう\n",
    "#     return K.mean(loss)\n",
    "# def loss(y_true, pred):\n",
    "#     return K.square(pred[1]-2*K.square(y_true-pred[0]))\n",
    "model.compile(optimizer=adam(lr=0.001),loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir=\"./\"+str(datetime.now().strftime('%s'))+\"model/\"\n",
    "model.fit(X_train,np.tile(y_train,100),\n",
    "         epochs=20,\n",
    "         batch_size=128,\n",
    "         shuffle=True,\n",
    "         validation_split=0.1,\n",
    "         callbacks=[TensorBoard(log_dir=logdir), \n",
    "                   EarlyStopping(patience=2),\n",
    "                   ModelCheckpoint(filepath = logdir+'model_epoch.{epoch:02d}-los{val_loss:.4f}.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='auto')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 結果の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor=K.function([model.input],[model.get_layer(\"mean\").output, model.get_layer(\"log_var\").output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_pred, log_var_pred = predictor([X_test])\n",
    "std_dev = np.exp(0.5*log_var_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper = mu_pred+std_dev\n",
    "lower = mu_pred-std_dev\n",
    "upper.shape, lower.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(mu_pred[:192])\n",
    "plt.fill_between(range(192),upper[:192,0],lower[:192,0],color=\"green\",alpha=0.2)\n",
    "plt.plot(y_test[:192])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(std_dev[:192])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
