{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.core.display import display\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from copy import deepcopy as cp\n",
    "\n",
    "##Visualization\n",
    "import plotly.offline as offline\n",
    "import plotly.graph_objs as go\n",
    "offline.init_notebook_mode()\n",
    "\n",
    "##visualization\n",
    "from ipywidgets import interact\n",
    "#from bokeh import mpl\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import output_notebook, show, push_notebook\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.palettes import Category10 as palette\n",
    "from bokeh.resources import INLINE\n",
    "output_notebook(resources=INLINE)\n",
    "import itertools\n",
    "\n",
    "##import sklearn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, precision_recall_curve, average_precision_score, auc\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFECV\n",
    "\n",
    "import boruta_py\n",
    "\n",
    "## statistical visualization\n",
    "from string import ascii_letters\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'Kozuka Gothic Pro'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## はじめに\n",
    "前回の記事で、変数選択(Feature Selection)についてまとめたので、実際に実装してみます。目的を見失うのを防ぐために、何が目的でどんなことをするのか実験設定を明記します。\n",
    "\n",
    "### 実験設定\n",
    "#### 目的\n",
    "いくつかの変数選択手法によって変数を選択し、モデルの改善を確かめる。\n",
    "#### 用いるデータ\n",
    "irisとかもう見すぎて飽きてるのでKaggleから取ってきました。\n",
    "https://www.kaggle.com/mlg-ulb/creditcardfraud/kernels\n",
    "\n",
    "このデータは、クレジットカードのデータから不正使用されたかどうか当てるタスクに用いることができます。ただしオリジナルデータは機密情報で会社としては公開できないので、このデータはオリジナルのデータをPCAしたものになります。説明変数の実態がなんなのかわからないのでハンドクラフトに特徴をピックアップすることができず、今回の変数選択手法を試すのにはぴったりなデータセットだと思います。ただし、Classが1であるサンプルが著しく少ないインバランスなデータです。中身を見てみるとこんな感じです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##acquire data\n",
    "df = pd.read_csv('./creditcard.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 用いる変数選択手法\n",
    "本記事のメインディッシュです。\n",
    "* Filter Method\n",
    "* Wrapper Method\n",
    "    * sklearn\n",
    "    * Boruta\n",
    "**(あとでもっと詳しく書こう)**\n",
    "\n",
    "#### 用いる判別器\n",
    "ロジスティック回帰を用いて行います。理由としては、計算が軽量であることや線形分離で判別できそうということが挙げられます。(あとで可視化します。)\n",
    "#### 評価指標\n",
    "10CVでRP-AUC(PR曲線の下側の面積)の標本平均を用います。PR曲線はROC曲線の親戚のようなもので、インバランスデータを評価するのに適しています。詳しくは過去の記事を見てください。\n",
    "** ULR挿入 **\n",
    "\n",
    "#### 行わないこと\n",
    "* インバランスへの対応(用いるデータはClass==1が著しく少ないデータになっています。)\n",
    "* パラメーターサーチ\n",
    "* このデータに対してどの判別器が適しているのか\n",
    "* クラス分類をするための閾値の設定\n",
    "* この判別に対して最終的なモデルを示す\n",
    "\n",
    "つまり、変数選択の結果、判定器が改善されたかだけを見ます。\n",
    "\n",
    "## データを少し見てみる\n",
    "datasetのV1~V3を可視化してみます。これだけでもなんとなく線形分離可能なんじゃないかと予想できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = df[df.Class == 0]\n",
    "df1 = df[df.Class == 1]\n",
    "##random under sampling\n",
    "df0u = df0.sample(frac = 0.04)\n",
    "## make trace\n",
    "trace0 = go.Scatter3d(\n",
    "    x = df0u.V1,\n",
    "    y = df0u.V2,\n",
    "    z = df0u.V3,\n",
    "    name = 'class0',\n",
    "    mode = 'markers',\n",
    "    #opacity = 0.4,\n",
    "    marker = dict(\n",
    "        size = 3\n",
    "    )\n",
    ")\n",
    "trace1 = go.Scatter3d(\n",
    "    x = df1.V1,\n",
    "    y = df1.V2,\n",
    "    z = df1.V3,\n",
    "    name = 'class1',\n",
    "    mode = 'markers',\n",
    "    marker = dict(\n",
    "        size = 3\n",
    "    )\n",
    ")\n",
    "## concatnate traces\n",
    "data = [trace0, trace1]\n",
    "\n",
    "## define layout\n",
    "layout = go.Layout(\n",
    "    title='3D-PCA',\n",
    "    width=700,\n",
    "    height=600,\n",
    "    scene = dict(\n",
    "        xaxis = dict(\n",
    "            nticks=4, range = [min(df.V1),max(df.V1)], title='V1'),\n",
    "        yaxis = dict(\n",
    "            nticks=4, range = [min(df.V2),max(df.V2)], title='V2'),\n",
    "        zaxis = dict(\n",
    "            nticks=4, range = [min(df.V3),max(df.V3)], title='V3')\n",
    "    ),\n",
    "    showlegend=True)\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## すべての特徴を用いた場合\n",
    "変数選択が有用ということを示すには、比較対象が必要です。すべての特徴を用いてロジスティック回帰を行った場合に、どれぐらいのスコアが出るのか確認してから変数選択した場合と比較しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##make matrix\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df.Class\n",
    "\n",
    "def print_pr_auc_score(X, y):\n",
    "    ##10-foldCV, LogisticRegression, PR_AUC\n",
    "    pr_auc = cross_val_score(LogisticRegression(), X, y, scoring=\"average_precision\", cv=10)\n",
    "    print('各分割でのスコア:',pr_auc)\n",
    "    print('\\nその平均:',np.mean(pr_auc))\n",
    "\n",
    "print_pr_auc_score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "すべての何も考えず特徴を用いたとき、**0.763**となりました。これを基準にします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Method\n",
    "まずFilter Methodによる変数選択を行ってみます。今回、特徴(説明変数)が連続値で、目的変数がカテゴリーなので、**前回の記事**の表に従うとLDAを用いて、目的変数に対して特徴が効いてるのか見ることになります。がしかし。sklearnで楽にやりたかったこともあり今回はANOVAのF値を指標にしました。これは、sklearn.feature_selection.SelectKBestでf_classif(判別分析用)を指定したときのスコアになります。\n",
    "ANOVAのF値については、いろいろ検索してみましたがこちらが私的にわかりやすいと感じました。(このF値とF分布を用いると検定の枠組みに持っていくことができて、その特徴がどの程度の確率で有意なのかも定量的に判断することができますが今回は考えないことにします。)http://www.ipc.shimane-u.ac.jp/food/kobayasi/anova.htm\n",
    "\n",
    "さて、では実際に変数選択してみましょう。まずは各クラスごとに各特徴の確率分布を描くことによって、効いてそうな特徴を目視で選択してみることにします。\n",
    "\n",
    "### 目視により選択\n",
    "すべての説明変数の確率分布を表示してみました。図が多いのでここではわかりやすい図だけ示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "for i in tqdm(range(len(df.columns)-1)):\n",
    "    g = sns.distplot(df0.iloc[:,i], color='green')\n",
    "    g = sns.distplot(df1.iloc[:,i], color='red') \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "線形分離でうまく両分布が分かれそうな特徴を選ぶと、V3, V4, V10, V11, V12, V14, V16となりました。これを使ってロジスティック回帰を評価して見ようと思います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##make matrix\n",
    "X = df[['V3','V4','V10','V11','V12','V14','V16']]\n",
    "y = df.Class\n",
    "\n",
    "##10-foldCV, LogisticRegression, PR_AUC\n",
    "pr_auc = cross_val_score(LogisticRegression(), X, y, scoring=\"average_precision\", cv=10)\n",
    "print('各分割でのスコア:',pr_auc)\n",
    "print('\\nその平均:',np.mean(pr_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目視で変数選択したときのスコアは**0.782**となりました。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn.feature_selection.SelectKBestによる選択\n",
    "目視ではなくもっと機械的に決めます。前述したようにANOVAのF値を用いています。その上位K個を返すといった関数です。\n",
    "ただし、いくつ変数が選ばれたらモデルとして良いのかわからないため、選ぶ変数の数を探索します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##make matrix\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df.Class\n",
    "\n",
    "scores=[]\n",
    "for n in tqdm(range(1,len(X.columns))):\n",
    "    print('\\n説明変数の数n=',n)\n",
    "    ##select features\n",
    "    select = SelectKBest(k=n)\n",
    "    select.fit(X, y)\n",
    "    mask = select.get_support()\n",
    "    X_selected = X.iloc[:,mask]\n",
    "    ##10-foldCV, LogisticRegression, PR_AUC\n",
    "    pr_auc = cross_val_score(LogisticRegression(), X_selected, y, scoring=\"average_precision\", cv=10)\n",
    "    scores.append(np.mean(pr_auc))    \n",
    "    print('平均のPR_AUC:',scores[n-1])\n",
    "\n",
    "    ## visualization\n",
    "    plt.matshow(mask.reshape(1, -1), cmap='gray_r')\n",
    "    plt.tick_params(labelleft = 'off')\n",
    "    plt.xlabel('使われた特徴. 黒が選択されたもの', fontsize=15)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルに使う特徴の数とスコアの関係を図示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = figure(\n",
    "    title = \"n vs. PR_AUC\", \n",
    "    plot_width=500, plot_height=500,\n",
    ")\n",
    "p.line(\n",
    "    range(1,len(scores)+1),\n",
    "    scores\n",
    ")\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21番目の説明変数を加えた途端スコアが大きく伸びました。21番目に追加された説明変数'Time'の確率分布を見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.distplot(df0.iloc[:,21], color='green')\n",
    "sns.distplot(df1.iloc[:,21], color='red')\n",
    "plt.xlim(-5, 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "分けられるか微妙ですが、もしかしたら他の変数に対するマルチコが少なく他の変数と組み合わせると有効に働くのかも知れません。上位5つの特徴だけを用いたときと、上位5つ＋'Time'を用いたときを比較しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##make matrix\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df.Class\n",
    "\n",
    "##select features\n",
    "select = SelectKBest(k=5)\n",
    "select.fit(X, y)\n",
    "mask = select.get_support()\n",
    "X_selected = pd.concat([df.Time, X.iloc[:,mask]], axis=1)\n",
    "##10-foldCV, LogisticRegression, PR_AUC\n",
    "pr_auc = cross_val_score(LogisticRegression(), X_selected, y, scoring=\"average_precision\", cv=10)\n",
    "print('上位5つのみのとき:',scores[4])\n",
    "print('上位5つ＋\\'Time\\'のとき:', np.mean(pr_auc) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timeも特徴に含めたほうが、結果として一番良いスコアが出ました。SelectKBestでは選ぶことができなかったので、FilterMethodを用いた結果としては、**0.782**の方を採用します。\n",
    "Timeは有用な変数だったにもかかわらず、SelectKBestで見逃されたようです。多重共線性を考慮できないのがFilterMethodの問題点です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapper Method\n",
    "### sklearn.feature_selection.RFECVによる選択\n",
    "recursive feature eliminationを用いた選択です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select = RFECV(LogisticRegression(), cv=10, scoring='average_precision')\n",
    "select.fit(X, y)\n",
    "mask = select.support_\n",
    "\n",
    "## visualization\n",
    "plt.matshow(mask.reshape(1, -1), cmap='gray_r')\n",
    "plt.tick_params(labelleft = 'off')\n",
    "plt.xlabel('使われた特徴. 黒が選択されたもの', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "選ばれた特徴でスコアを算出します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('選ばれた変数の数',select.n_features_)\n",
    "print('各変数のランキング',select.ranking_)\n",
    "select.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_selected = X.iloc[:,mask]\n",
    "##10-foldCV, LogisticRegression, PR_AUC\n",
    "pr_auc = cross_val_score(LogisticRegression(), X_selected, y, scoring=\"average_precision\", cv=10)\n",
    "print('平均のPR_AUC:',np.mean(pr_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先程と同じように'Time'が選ばれていません。問題となったTimeも加えて評価してみました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_selected = pd.concat([df.Time, X.iloc[:,mask]], axis=1)\n",
    "##10-foldCV, LogisticRegression, PR_AUC\n",
    "pr_auc = cross_val_score(LogisticRegression(), X_selected, y, scoring=\"average_precision\", cv=10)\n",
    "print('\\'Time\\'を加えたのとき:', np.mean(pr_auc) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "少しだけスコアが上がりました。しかしこれもRFECVが自動的に選んではくれなかったものなので、ここでのスコアは**0.788**とします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Borutaによる変数選択\n",
    "これはrandomForestを用いた変数選択手法の一つで、詳しいアルゴリズムはこちらの3ページに書いてあります。https://www.google.co.jp/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&ved=0ahUKEwiEzMP4p9naAhWBk5QKHbRjC9oQFggoMAA&url=https%3A%2F%2Fwww.jstatsoft.org%2Farticle%2Fview%2Fv036i11%2Fv36i11.pdf&usg=AOvVaw3tyiHN0BCe2fkkAA6xEVDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##make matrix\n",
    "X = df.drop('Class', axis=1).values\n",
    "y = df.Class.values\n",
    "\n",
    "forest = RandomForestClassifier()\n",
    "# define Boruta feature selection method\n",
    "select = boruta_py.BorutaPy(forest, n_estimators=10)\n",
    "select.fit(X, y)\n",
    "mask = select.support_\n",
    "\n",
    "## visualization\n",
    "plt.matshow(mask.reshape(1, -1), cmap='gray_r')\n",
    "plt.tick_params(labelleft = 'off')\n",
    "plt.xlabel('使われた特徴. 黒が選択されたもの', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_selected = df.iloc[:,mask]\n",
    "##10-foldCV, LogisticRegression, PR_AUC\n",
    "pr_auc = cross_val_score(LogisticRegression(), X_selected, y, scoring=\"average_precision\", cv=10)\n",
    "print('平均のPR_AUC:',np.mean(pr_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**0.796**というスコアになりました。適当にパラメーターを決めたり、ロジスティック回帰でいいのかという疑問はありますが、ひとまずこれを採用したいと思います。また、計算時間に関しては、2.5GHzCorei5で4時間程度かかりました。計算中はメモリも2GBぐらい持っていかれたと思います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
