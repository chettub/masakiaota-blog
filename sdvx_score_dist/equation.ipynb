{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "あるレベル帯の曲の難易度は全て同じだと仮定する。新曲が追加されたときに、自分がその曲をプレイするとどれぐらいの得点が取れそうか知りたい。というのも、音楽ゲームは100円で3曲プレイできるが、得点によっては次の曲に進めない制約があるからである。100円でより多くの曲をプレイするためには、リスクを取りたくない。得点を確率分布に落とし込むことで、このリスクを定量評価できる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 仮定\n",
    "- 同じレベル帯の曲は同じ難易度である。(同じレベルなら曲$_i$のスコアの分布$X_i$は全て同じ分布)\n",
    "- プレイヤーのスキルは上昇しないものとする。\n",
    "\n",
    "以下の同じレベル帯で考えることにする。\n",
    "\n",
    "- プレイごとに得られるスコアは独立同分布である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 知りたい\n",
    "曲を一回プレイしたときに獲得するスコアXの分布$f^{(X)}(x)$\n",
    "\n",
    "#### 知っている\n",
    "曲$_i$を$n_i$回プレイしたときの最大のスコア$m_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ノーテーション\n",
    "ここで議論する曲の背景に存在する難易度は同じと仮定する。\n",
    "\n",
    "曲が1〜Nまであるとする。\n",
    "\n",
    "$n_i$...曲$_i$をプレイした回数\n",
    "\n",
    "曲を一回プレイしてスコアを得ることを1回の試行とする。\n",
    "\n",
    "$X_{(i,j)}$...曲$_i$をプレイした中でj回目に出たスコア。\n",
    "\n",
    "過去の全ての試行を確率変数として表すと以下のようになる。\n",
    "\n",
    "| 曲  | 過去の全ての試行 |\n",
    "| :-------------: | :-------------: |\n",
    "| 1  |  $X_{(1,1)}$,$X_{(1,2)}$,...,$X_{(1,n_{1})}$ |\n",
    "| 2  | $X_{(2,1)}$,$X_{(2,2)}$,...,$X_{(2,n_{2})}$  |\n",
    "| ...  | ...  |\n",
    "| N  | $X_{(N,1)}$,$X_{(N,2)}$,...,$X_{(N,n_{N})}$  |\n",
    "\n",
    "これらは全て独立同分布に従うと仮定する。またその分布に従う確率変数を$X$と代表して書くことにする。\n",
    " \n",
    "$X$...ある曲を一回プレイしたときに得られるスコアの確率変数。\n",
    "\n",
    "$f^{(X)}(x)$...推定したい$X$の従う確率分布。\n",
    "\n",
    "今手元にあるデータは\n",
    "\n",
    "| 曲  | ベストスコア | プレイ回数 |\n",
    "| :-------------: | :-------------: | :-----------: |\n",
    "| 1  |  max($X_{(1,1)}$,$X_{(1,2)}$,...,$X_{(1,n_{1})}$) | $n_1$ |\n",
    "| 2  | max($X_{(2,1)}$,$X_{(2,2)}$,...,$X_{(2,n_{2})}$)  | $n_2$ |\n",
    "| ...  | ...  | ... |\n",
    "| N  | max($X_{(N,1)}$,$X_{(N,2)}$,...,$X_{(N,n_{N})}$)  | $n_N$ |\n",
    "\n",
    "\n",
    "ベストスコアは確率変数の最大値なのでこれも確率変数である。\n",
    "$$M_{n_i}=max(X_{(i,1)},X_{(i,2)},...,X_{(i,n_{i})})$$\n",
    "と定義すると、表は以下のようにスッキリとした見た目になる。\n",
    "\n",
    "| 曲  | ベストスコア | プレイ回数 |\n",
    "| :-------------: | :-------------: | :-----------: |\n",
    "| 1  |$M_{n_i}$| $n_1$ |\n",
    "| 2  |$M_{n_2}$| $n_2$ |\n",
    "| ...  | ...  | ... |\n",
    "| N  |$M_{n_N}$| $n_N$ |\n",
    "\n",
    "\n",
    "$M_n$...n回試行したときの最大値の確率変数。\n",
    "\n",
    "$f^{(M_n)}(m)$...$M_n$の従う確率密度関数。\n",
    "\n",
    "もう一度、目的を確認しておこう。ベストスコアとプレイ回数のデータから、曲を一回プレイしたときに得られる得点$X$の確率分布を求めたいというのが目的である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 式\n",
    "$f^{(X)}(x)$を$f^{(M_n)}(m)$から推定したい。ここで$f^{(X)}(x)$はパラメーター$\\boldsymbol\\theta$によって表現できるものとする。\n",
    "そのため$f^{(X)}(x ; \\boldsymbol\\theta)$と書くことにする。$f^{(X)}(x ; \\boldsymbol\\theta)$を求めるとはこのパラメーター$\\boldsymbol\\theta$を求めることである。\n",
    "$\\boldsymbol\\theta$を求めるために以下の手続きを取る。\n",
    "\n",
    "\n",
    "1. $f^{(X)}(x; \\boldsymbol\\theta)$を使って,最大値の分布$f^{(M_n)}(m ; \\boldsymbol\\theta)$を構築する。(ここで示した$\\boldsymbol\\theta$は$f^{(X)}(x ; \\boldsymbol\\theta)$のパラメーターに共通)\n",
    "2. $f^{(M_n)}(m ; \\boldsymbol\\theta)$の負の対数尤度関数を構築する。\n",
    "3. 2を損失関数とみなし、最小となるパラメーター$\\boldsymbol\\theta$を探す。ここでは$X$に分布を仮定して具体的な計算式にまで落とし込む。\n",
    "\n",
    "\n",
    "これらについて一つ一つ式変形をしていこう。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1について\n",
    "確率密度関数$f(\\cdot)$に対して累積密度関数を$F(\\cdot)$と書くことにする。$P(\\cdot)$を$\\cdot$に記載された条件を満たす確率と定義する。このとき、最大値の分布を考えてみる。\n",
    "最大値の分布は以下の式から議論をスタートしよう。\n",
    "\n",
    "$$P(M_n < m)  = \\left(P(X < m)\\right)^n $$\n",
    "\n",
    "これは、｢最大値の確率変数$M$が$m$より小さい確率は、全ての$X$が$m$より小さい確率と一致する｣という内容を記述する式である。これを累積分布関数に書き換えれば、\n",
    "\n",
    "$$ F^{(M_n)}(m) = \\left(F^{(X)}(m)\\right)^n $$\n",
    "\n",
    "となる。\n",
    "\n",
    "したがって、$f^{(M_n)}(m)$は以下のように表せる。\n",
    "\n",
    "$$ f^{(M_n)}(m) = \\frac{d}{dm}F^{(M_n)}(m) $$\n",
    "\n",
    "$$ f^{(M_n)}(m) = \\frac{d}{dm}\\left(F^{(X)}(m)\\right)^n $$\n",
    "\n",
    "$$ f^{(M_n)}(m) = n \\left(F^{(X)}(m)\\right)^{n-1}\\frac{d}{dm}\\left(F^{(X)}(m)\\right) $$\n",
    "\n",
    "$$ f^{(M_n)}(m) = n \\left(F^{(X)}(m)\\right)^{n-1}f^{(X)}(m)  $$\n",
    "\n",
    "式の形を少し整理して、パラメーター$\\boldsymbol\\theta$を自明に書くと以下になる。\n",
    "\n",
    "$$ f^{(M_n)}(m ; \\boldsymbol\\theta) = n f^{(X)}(m;\\boldsymbol\\theta) \\left(F^{(X)}(m;\\boldsymbol\\theta)\\right)^{n-1} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2について\n",
    "N個の曲について、プレイした回数とベストスコアはわかっている。これについて負の対数尤度関数を構築することを考える。\n",
    "\n",
    "$$\\text{負の対数尤度} = -\\ln\\left(\\prod_i^N f^{(M_{n_i})}(m_i ; \\boldsymbol\\theta)\\right)$$\n",
    "\n",
    "となる。1の結果を代入し形を整えると以下のようになる。\n",
    "\n",
    "$$\\text{負の対数尤度} = -\\sum_i^N \\ln\\left( f^{(M_{n_i})}(m_i ; \\boldsymbol\\theta)\\right)$$\n",
    "\n",
    "$$\\text{負の対数尤度} = -\\sum_i^N \\ln\\left( n_i f^{(X)}(m_i;\\boldsymbol\\theta) \\left(F^{(X)}(m_i;\\boldsymbol\\theta)\\right)^{n_i-1} \\right)$$\n",
    "\n",
    "$$\\text{負の対数尤度} = -\\sum_i^N \\left[ \\ln n_i + \\ln f^{(X)}(m_i;\\boldsymbol\\theta) + (n_i-1)\\ln \\left(F^{(X)}(m_i;\\boldsymbol\\theta)\\right) \\right]$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3について\n",
    "2で求めた負の対数尤度をもとに、$\\boldsymbol\\theta$についての損失関数を定義すると、\n",
    "$$loss(\\boldsymbol\\theta)=-\\sum_i^N \\left[ \\ln f^{(X)}(m_i;\\boldsymbol\\theta) + (n_i-1)\\ln \\left(F^{(X)}(m_i;\\boldsymbol\\theta)\\right) \\right]$$\n",
    "となる。\n",
    "\n",
    "これは見ての通り、$X$についての分布$f^{(X)}(m_i;\\boldsymbol\\theta)$を仮定しないと損失が計算できない形式になっている。\n",
    "\n",
    "そこで、今回は$f^{(X)}(m_i;\\boldsymbol\\theta)$にベータ分布を仮定した。これは、5年間プレイしてきての経験と、実際にランダムに選曲してスコアを実測した結果から来る仮定である。(実測のヒストグラムは付録に示す)\n",
    "\n",
    "つまり\n",
    "$$f^{(X)}(x;\\boldsymbol\\theta)=\\frac{x^{a-1}(1-x)^{b-1}}{B(a,b)}(=Beta(x; a,b))$$\n",
    "である。ただし、$B(\\cdot)$はベータ関数で、\n",
    "$$B(a,b)=\\int_0^1 x^{a-1}(1-x)^{b-1} dx$$\n",
    "である。\n",
    "\n",
    "これを先の損失関数に代入すると、\n",
    "$$loss(a,b)=-\\sum_i^N \\left[ \\ln \\frac{m_i^{a-1}(1-m_i)^{b-1}}{B(a,b)} + (n_i-1)\\ln \\int_0^{m_i} \\frac{m_i^{a-1}(1-m_i)^{b-1}}{B(a,b)} dm_i \\right]$$\n",
    "\n",
    "\n",
    "$$loss(a,b)=-\\sum_i^N \\left[ -\\ln B(a,b) + \\ln (m_i^{a-1}(1-m_i)^{b-1}) + (n_i-1)\\ln \\int_0^{m_i} \\frac{m_i^{a-1}(1-m_i)^{b-1}}{B(a,b)} dm_i \\right]$$\n",
    "\n",
    "$$loss(a,b)=-\\sum_i^N \\left[ -\\ln B(a,b) + (a-1)\\ln m_i + (b-1)\\ln(1-m_i) + (n_i-1)\\ln \\int_0^{m_i} \\frac{m_i^{a-1}(1-m_i)^{b-1}}{B(a,b)} dm_i \\right]$$\n",
    "\n",
    "シグマの中の第4項目の積分は正則化された不完全ベータ関数と言われるものである。表記を簡単にするために、\n",
    "$$I_x(a,b) = \\int_0^{x} \\frac{x^{a-1}(1-x)^{b-1}}{B(a,b)} dx$$\n",
    "とおくと、損失関数は結局\n",
    "\n",
    "$$loss(a,b)=-\\sum_i^N \\left[ -\\ln B(a,b) + (a-1)\\ln m_i + (b-1)\\ln(1-m_i) + (n_i-1)\\ln I_x(a,b) \\right]$$\n",
    "\n",
    "$$loss(a,b)=\\sum_i^N \\left[ \\ln B(a,b) - (a-1)\\ln m_i - (b-1)\\ln(1-m_i) - (n_i-1)\\ln I_x(a,b) \\right]$$\n",
    "\n",
    "となる。\n",
    "\n",
    "ゴールは、\n",
    "$$a,b = \\arg \\min_{a,b} loss(a,b)$$\n",
    "を求めることである。\n",
    "\n",
    "ここではa,bをグリッド状に全探索することで、損失関数を最小化するパラメーターを探索する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import betaln, betainc, beta\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(a,b,ns:np.array,ms:np.array):\n",
    "    firstitem=ns+lnbeta_a_b\n",
    "    seconditem=-(a-1)*np.log(ms)\n",
    "    thirditem=-(b-1)*np.log(1-ms)\n",
    "    fourthitem=-(ns-1)*np.log(betainc(a,b,ms))\n",
    "    \n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.19, 0.36, 1.  ])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betainc(1,2,np.array([0.1,0.2,1])) #これ普通の不完全ベータ関数ではなくて正規化された不完全ベータ関数じゃん"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.e**betaln(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.functional as func\n",
    "import pyro.distributions as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoge=dist.Beta(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-6e8897be53b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhoge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0micdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36micdf\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \"\"\"\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0menumerate_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hoge.icdf(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-69781071fe1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhoge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.0.0/lib/python3.6/site-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36mcdf\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \"\"\"\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0micdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hoge.cdf(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3000])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor([0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\psi(x) = \\frac{d}{dx} \\ln\\left(\\Gamma\\left(x\\right)\\right) = \\frac{\\Gamma'(x)}{\\Gamma(x)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#実装ではベータ関数はガンマ関数から自分で実装する必要がありそう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12.8018])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.lgamma(torch.Tensor([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$loss(a,b)=-\\sum_i^N \\left[ -n_i\\ln B(a,b) + \\ln (m_i^{a-1}(1-m_i)^{b-1}) + (n_i-1)\\ln \\int_0^{m_i} m_i^{a-1}(1-m_i)^{b-1} dm_i \\right]$$\n",
    "\n",
    "$$loss(a,b)=-\\sum_i^N \\left[ -n_i\\ln B(a,b) + (a-1)\\ln m_i + (b-1)\\ln(1-m_i) + (n_i-1)\\ln \\int_0^{m_i} m_i^{a-1}(1-m_i)^{b-1} dm_i \\right]$$\n",
    "\n",
    "シグマの中の第4項の積分は不完全ベータ関数である。簡単のために\n",
    "$$B_x(a,b)\\int_0^{x} x^{a-1}(1-x)^{b-1} dx$$\n",
    "と記号を定義すると、損失関数は、\n",
    "\n",
    "$$loss(a,b)=-\\sum_i^N \\left[ -n_i\\ln B(a,b) + (a-1)\\ln m_i + (b-1)\\ln(1-m_i) + (n_i-1)\\ln B_{m_i}(a,b) \\right]$$\n",
    "\n",
    "$$loss(a,b)=\\sum_i^N \\left[ +n_i\\ln B(a,b) - (a-1)\\ln m_i - (b-1)\\ln(1-m_i) - (n_i-1)\\ln B_{m_i}(a,b) \\right]$$\n",
    "\n",
    "\n",
    "となる。\n",
    "\n",
    "ゴールは、\n",
    "$$a,b = \\arg \\min_{a,b} loss(a,b)$$\n",
    "を求めることである。\n",
    "\n",
    "ここではa,bをグリッド状に全探索することで、損失関数を最小化するパラメーターを探索する。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
